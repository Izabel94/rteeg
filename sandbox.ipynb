{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "from mne.time_frequency import psd_multitaper\n",
    "from mne import find_events, write_events\n",
    "from mne.io import RawArray\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pylsl import local_clock\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import rteeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for EEG stream ... \n",
      "Searching for Markers stream ... \n",
      "Connected to Markers stream. \n",
      "Connected to EEG stream. \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from mne import find_events\n",
    "import rteeg\n",
    "rt = rteeg.Stream()\n",
    "rt.connect(eeg=True, markers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26665426299587125"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.eeg_latency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_times = [0]\n",
    "n_samples = [0]\n",
    "def debug_func(global_times_, n_samples_):\n",
    "    n_samples_1 = len(rt._eeg_data)\n",
    "    delta_n_samples = n_samples_1 - n_samples_[-1]\n",
    "    n_samples_.append(n_samples_1)\n",
    "\n",
    "    \n",
    "    if global_times_:\n",
    "        t1 = time.time()\n",
    "        t_delta_main = t1 - global_times_[-1]\n",
    "        global_times_.append(t1)\n",
    "    else:\n",
    "        global_times_.append(time.time())\n",
    "        t_delta_main = 0.\n",
    "    \n",
    "    \n",
    "    true_last_event = rt._marker_data[-1][0]\n",
    "    latency = rt.eeg_latency()\n",
    "    # time.sleep(latency)\n",
    "    last_event = find_events(rt.make_raw(5))[-1, 2]\n",
    "    \n",
    "    out = (\"{:.2f}\\t{:.2f}\\t\\t{}\\t\\t{}\\t\\t{}\"\n",
    "          \"\".format(latency, t_delta_main, last_event, true_last_event, delta_n_samples))\n",
    "    print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency\tDelta-time\tlast event\ttrue last\tn_samples\n",
      "1.89\t1482275022.92\t\t557\t\t558\t\t233615\n",
      "2.68\t3.80\t\t558\t\t559\t\t1502\n",
      "1.71\t2.03\t\t560\t\t560\t\t1502\n",
      "1.04\t2.34\t\t561\t\t562\t\t1500\n",
      "0.69\t2.64\t\t563\t\t563\t\t1500\n",
      "1.24\t3.55\t\t564\t\t565\t\t1500\n"
     ]
    }
   ],
   "source": [
    "print \"Latency\\tDelta-time\\tlast event\\ttrue last\\tn_samples\"\n",
    "loop = rteeg.LoopAnalysis(rt, 3, debug_func, (global_times, n_samples),\n",
    "                          show_window=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop of analysis stopped.\n"
     ]
    }
   ],
   "source": [
    "loop.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "these_times = []\n",
    "\n",
    "def analysis_func(list_, global_times):\n",
    "    output_base = \"\"\"\n",
    "    <head>\n",
    "        <style>\n",
    "        table {{font-size: 30px;}}\n",
    "        th, td {{\n",
    "            background-color: white;\n",
    "            text-align: center;\n",
    "            padding: 20px;\n",
    "        }}\n",
    "\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "\n",
    "        <table align=\"center\">\n",
    "            <tr>\n",
    "                <th>Prediction</th>\n",
    "                <th>EEG samples (N)</th>\n",
    "                <th>Time since last prediction</th>\n",
    "                <th>Latency</th>\n",
    "                <th>i</th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color:{color}\"><b>{prediction}</b></td>\n",
    "                <td>{n_samples}</td>\n",
    "                <td>{t_delta_main:.4f}</td>\n",
    "                <td>{latency:.2f}</td>\n",
    "                <td>{i}</td>\n",
    "            </tr>\n",
    "        </table>\n",
    "\n",
    "    </body>\n",
    "    \"\"\"\n",
    "    n_samples = len(stream._eeg_data)\n",
    "    event_id = {\n",
    "        1: [\"Class 1\", \"green\"],\n",
    "        2: [\"Class 2\", \"red\"],\n",
    "    }\n",
    "\n",
    "    y_pred = random.choice(event_id.keys())\n",
    "    list_.append(y_pred)\n",
    "    \n",
    "    if global_times:\n",
    "        t1 = time.time()\n",
    "        t_delta_main = t1 - global_times[-1]\n",
    "        global_times.append(t1)\n",
    "    else:\n",
    "        global_times.append(time.time())\n",
    "        t_delta_main = 0.\n",
    "        \n",
    "    out = output_base.format(prediction=event_id[y_pred][0],\n",
    "                             color=event_id[y_pred][1],\n",
    "                             n_samples=n_samples,\n",
    "                             latency=stream.eeg_latency(),\n",
    "                             t_delta_main=t_delta_main,\n",
    "                             i=len(list_))\n",
    "    t_delta_main = None\n",
    "    \n",
    "    return out\n",
    "\n",
    "loop = rteeg.LoopAnalysis(stream, 1, analysis_func, (predictions, these_times), \n",
    "                          show_window=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from threading import Thread, Event\n",
    "from pylsl import local_clock\n",
    "\n",
    "class ContinuousResolver(object):\n",
    "    \"\"\"Class to continously update the latency\n",
    "    of the EEG recording.\"\"\"\n",
    "    def __init__(self, stream):\n",
    "        \n",
    "        self.stream = stream\n",
    "        self.latency = 0.\n",
    "        self.i = 0\n",
    "        self.stopped = Event()\n",
    "        \n",
    "        # Raise error if EEG stream not started.\n",
    "        self.stream._check_if_stream_active('EEG')\n",
    "        \n",
    "        thread = Thread(target=self._resolve, name=\"Latency-resolver\")\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "        \n",
    "    def _resolve(self):\n",
    "        # Get measure of latency every 10 ms.\n",
    "        while not self.stopped.wait(0.01):\n",
    "            self.latency = local_clock() - self.stream._eeg_data[-1][-1]\n",
    "            if self.latency > 3.:\n",
    "                self.i += 1\n",
    "            \n",
    "    def stop(self):\n",
    "        self.stopped.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resolve = ContinuousResolver(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print resolve.latency\n",
    "print(local_clock() - rt._eeg_data[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print rt._eeg_data[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resolve.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(rt._eeg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rt.recording_duration()\n",
    "print rt.eeg_latency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for __ in range(10):\n",
    "    print rt.eeg_latency()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = stream._get_raw_eeg_data()\n",
    "events = stream.make_events(data)\n",
    "print events.shape\n",
    "data[-1,:] = 0\n",
    "raw = RawArray(data, stream.info)\n",
    "raw.add_events(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events = find_events(raw, shortest_event=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_events(\"rteeg_test_Dec8-events.fif\", events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw.info['events'] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_events(raw, shortest_event=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw.save('rteeg_test_Dec8-raw.fif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_events(raw, shortest_event=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stream = rteeg.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stream.connect(eeg=True, markers=False, eeg_montage='Enobio32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stream.recording_duration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = stream.make_raw()\n",
    "# raw.plot()\n",
    "print find_events(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stream.fit_ica(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = stream.make_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = stream.make_raw(10)\n",
    "events = find_events(raw)\n",
    "print events\n",
    "raw.plot(events=events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "these_times = []\n",
    "\n",
    "def analysis_func(list_, global_times):\n",
    "    output_base = \"\"\"\n",
    "    <head>\n",
    "        <style>\n",
    "        table {{font-size: 30px;}}\n",
    "        th, td {{\n",
    "            background-color: white;\n",
    "            text-align: center;\n",
    "            padding: 20px;\n",
    "        }}\n",
    "\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "\n",
    "        <table align=\"center\">\n",
    "            <tr>\n",
    "                <th>Prediction</th>\n",
    "                <th>EEG samples (N)</th>\n",
    "                <th>Time since last prediction</th>\n",
    "                <th>Latency</th>\n",
    "                <th>i</th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color:{color}\"><b>{prediction}</b></td>\n",
    "                <td>{n_samples}</td>\n",
    "                <td>{t_delta_main:.4f}</td>\n",
    "                <td>{latency:.2f}</td>\n",
    "                <td>{i}</td>\n",
    "            </tr>\n",
    "        </table>\n",
    "\n",
    "    </body>\n",
    "    \"\"\"\n",
    "    n_samples = len(stream._eeg_data)\n",
    "    event_id = {\n",
    "        1: [\"Class 1\", \"green\"],\n",
    "        2: [\"Class 2\", \"red\"],\n",
    "    }\n",
    "\n",
    "    y_pred = random.choice(event_id.keys())\n",
    "    list_.append(y_pred)\n",
    "\n",
    "#     t0 = time.time()\n",
    "#     raw = stream.make_raw(10)\n",
    "#     raw.filter(1., 40)\n",
    "#     psd, freqs= psd_multitaper(raw, fmin=1., fmax=7.0)\n",
    "#     psd_scaled = StandardScaler().fit_transform(psd)\n",
    "#     pca = PCA(n_components=15).fit_transform(psd_scaled)\n",
    "#     t_delta = time.time() - t0\n",
    "    \n",
    "    if global_times:\n",
    "        t1 = time.time()\n",
    "        t_delta_main = t1 - global_times[-1]\n",
    "        global_times.append(t1)\n",
    "    else:\n",
    "        global_times.append(time.time())\n",
    "        t_delta_main = 0.\n",
    "        \n",
    "    out = output_base.format(prediction=event_id[y_pred][0],\n",
    "                             color=event_id[y_pred][1],\n",
    "                             n_samples=n_samples,\n",
    "                             latency=stream.eeg_latency(),\n",
    "                             t_delta_main=t_delta_main,\n",
    "                             i=len(list_))\n",
    "    t_delta_main = None\n",
    "    \n",
    "    return out\n",
    "\n",
    "loop = rteeg.LoopAnalysis(stream, 1, analysis_func, (predictions, these_times), \n",
    "                          show_window=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
